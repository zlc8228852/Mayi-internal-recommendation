{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 修改pandas默认的现实设置\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns',10)  \n",
    "pd.set_option('display.max_rows',20)  \n",
    "#禁用科学计数法\n",
    "np.set_printoptions(suppress=True,   precision=10,  threshold=2000,  linewidth=150)  \n",
    "pd.set_option('display.float_format',lambda x : '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 赛题模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 导入工具\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.linear_model import LinearRegression  #线性回归\n",
    "from sklearn.neighbors import KNeighborsRegressor  #K近邻回归\n",
    "from sklearn.tree import DecisionTreeRegressor  #决策树回归\n",
    "from sklearn.ensemble import RandomForestRegressor  #随机森林回归\n",
    "from sklearn.svm import SVR  #支持向量回归\n",
    "from sklearn.model_selection import train_test_split  # 切分数据\n",
    "from sklearn.metrics import mean_squared_error  #评价指标\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取数据\n",
    "train_data_file = \"./zhengqi_train.txt\"\n",
    "test_data_file =  \"./zhengqi_test.txt\"\n",
    "train_data = pd.read_csv(train_data_file, sep='\\t', encoding='utf-8')\n",
    "test_data = pd.read_csv(test_data_file, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制各个特征的箱线图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBsAAAI+CAYAAAD98wJ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrGLYAAAAAAAArPoJ8DiJUQiSc+YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x262878542e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18, 10))\n",
    "plt.boxplot(x=train_data.values,labels=train_data.columns)\n",
    "plt.hlines([-7.5, 7.5], 0, 40, colors='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 删除异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.184404</td>\n",
       "      <td>-0.083912</td>\n",
       "      <td>-0.434762</td>\n",
       "      <td>0.101671</td>\n",
       "      <td>-0.019172</td>\n",
       "      <td>0.838049</td>\n",
       "      <td>-0.274092</td>\n",
       "      <td>-0.173971</td>\n",
       "      <td>-0.266709</td>\n",
       "      <td>0.255114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206871</td>\n",
       "      <td>-0.146463</td>\n",
       "      <td>-0.083215</td>\n",
       "      <td>-0.191729</td>\n",
       "      <td>-0.030782</td>\n",
       "      <td>-0.011433</td>\n",
       "      <td>-0.009985</td>\n",
       "      <td>-0.296895</td>\n",
       "      <td>-0.046270</td>\n",
       "      <td>0.195735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.073333</td>\n",
       "      <td>1.076670</td>\n",
       "      <td>0.969541</td>\n",
       "      <td>1.034925</td>\n",
       "      <td>1.147286</td>\n",
       "      <td>0.963043</td>\n",
       "      <td>1.054119</td>\n",
       "      <td>1.040101</td>\n",
       "      <td>1.085916</td>\n",
       "      <td>1.014394</td>\n",
       "      <td>...</td>\n",
       "      <td>1.064140</td>\n",
       "      <td>0.880593</td>\n",
       "      <td>1.126414</td>\n",
       "      <td>1.138454</td>\n",
       "      <td>1.130228</td>\n",
       "      <td>0.989732</td>\n",
       "      <td>0.995213</td>\n",
       "      <td>0.946896</td>\n",
       "      <td>1.040854</td>\n",
       "      <td>0.940599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.814000</td>\n",
       "      <td>-5.488000</td>\n",
       "      <td>-4.283000</td>\n",
       "      <td>-3.276000</td>\n",
       "      <td>-4.921000</td>\n",
       "      <td>-1.168000</td>\n",
       "      <td>-5.649000</td>\n",
       "      <td>-5.625000</td>\n",
       "      <td>-6.059000</td>\n",
       "      <td>-6.784000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.435000</td>\n",
       "      <td>-2.413000</td>\n",
       "      <td>-4.507000</td>\n",
       "      <td>-7.698000</td>\n",
       "      <td>-4.057000</td>\n",
       "      <td>-4.627000</td>\n",
       "      <td>-4.789000</td>\n",
       "      <td>-7.477000</td>\n",
       "      <td>-2.608000</td>\n",
       "      <td>-3.346000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.664000</td>\n",
       "      <td>-0.451000</td>\n",
       "      <td>-0.978000</td>\n",
       "      <td>-0.644000</td>\n",
       "      <td>-0.497000</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>-0.732000</td>\n",
       "      <td>-0.509000</td>\n",
       "      <td>-0.775000</td>\n",
       "      <td>-0.390000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.453000</td>\n",
       "      <td>-0.818000</td>\n",
       "      <td>-0.339000</td>\n",
       "      <td>-0.476000</td>\n",
       "      <td>-0.472000</td>\n",
       "      <td>-0.460000</td>\n",
       "      <td>-0.290000</td>\n",
       "      <td>-0.349000</td>\n",
       "      <td>-0.593000</td>\n",
       "      <td>-0.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>-0.267000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.437000</td>\n",
       "      <td>-0.082000</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>-0.004000</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.445000</td>\n",
       "      <td>-0.199000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>-0.270000</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.549000</td>\n",
       "      <td>0.589000</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.793000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>1.928000</td>\n",
       "      <td>0.457000</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.482000</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.434000</td>\n",
       "      <td>0.468000</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>0.471000</td>\n",
       "      <td>0.627000</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>0.273000</td>\n",
       "      <td>0.364000</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>0.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.100000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>1.946000</td>\n",
       "      <td>2.603000</td>\n",
       "      <td>4.475000</td>\n",
       "      <td>3.176000</td>\n",
       "      <td>1.528000</td>\n",
       "      <td>1.394000</td>\n",
       "      <td>2.408000</td>\n",
       "      <td>1.766000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.656000</td>\n",
       "      <td>3.022000</td>\n",
       "      <td>3.139000</td>\n",
       "      <td>1.428000</td>\n",
       "      <td>2.299000</td>\n",
       "      <td>5.465000</td>\n",
       "      <td>5.110000</td>\n",
       "      <td>1.671000</td>\n",
       "      <td>2.861000</td>\n",
       "      <td>3.021000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                V0           V1           V2           V3           V4  \\\n",
       "count  1925.000000  1925.000000  1925.000000  1925.000000  1925.000000   \n",
       "mean     -0.184404    -0.083912    -0.434762     0.101671    -0.019172   \n",
       "std       1.073333     1.076670     0.969541     1.034925     1.147286   \n",
       "min      -4.814000    -5.488000    -4.283000    -3.276000    -4.921000   \n",
       "25%      -0.664000    -0.451000    -0.978000    -0.644000    -0.497000   \n",
       "50%       0.065000     0.195000    -0.267000     0.220000     0.118000   \n",
       "75%       0.549000     0.589000     0.278000     0.793000     0.610000   \n",
       "max       2.100000     2.120000     1.946000     2.603000     4.475000   \n",
       "\n",
       "                V5           V6           V7           V8           V9  \\\n",
       "count  1925.000000  1925.000000  1925.000000  1925.000000  1925.000000   \n",
       "mean      0.838049    -0.274092    -0.173971    -0.266709     0.255114   \n",
       "std       0.963043     1.054119     1.040101     1.085916     1.014394   \n",
       "min      -1.168000    -5.649000    -5.625000    -6.059000    -6.784000   \n",
       "25%       0.122000    -0.732000    -0.509000    -0.775000    -0.390000   \n",
       "50%       0.437000    -0.082000     0.018000    -0.004000     0.401000   \n",
       "75%       1.928000     0.457000     0.515000     0.482000     0.904000   \n",
       "max       3.176000     1.528000     1.394000     2.408000     1.766000   \n",
       "\n",
       "          ...               V28          V29          V30          V31  \\\n",
       "count     ...       1925.000000  1925.000000  1925.000000  1925.000000   \n",
       "mean      ...         -0.206871    -0.146463    -0.083215    -0.191729   \n",
       "std       ...          1.064140     0.880593     1.126414     1.138454   \n",
       "min       ...         -2.435000    -2.413000    -4.507000    -7.698000   \n",
       "25%       ...         -0.453000    -0.818000    -0.339000    -0.476000   \n",
       "50%       ...         -0.445000    -0.199000     0.010000     0.100000   \n",
       "75%       ...         -0.434000     0.468000     0.447000     0.471000   \n",
       "max       ...          4.656000     3.022000     3.139000     1.428000   \n",
       "\n",
       "               V32          V33          V34          V35          V36  \\\n",
       "count  1925.000000  1925.000000  1925.000000  1925.000000  1925.000000   \n",
       "mean     -0.030782    -0.011433    -0.009985    -0.296895    -0.046270   \n",
       "std       1.130228     0.989732     0.995213     0.946896     1.040854   \n",
       "min      -4.057000    -4.627000    -4.789000    -7.477000    -2.608000   \n",
       "25%      -0.472000    -0.460000    -0.290000    -0.349000    -0.593000   \n",
       "50%       0.155000    -0.040000     0.160000    -0.270000     0.083000   \n",
       "75%       0.627000     0.419000     0.273000     0.364000     0.651000   \n",
       "max       2.299000     5.465000     5.110000     1.671000     2.861000   \n",
       "\n",
       "               V37  \n",
       "count  1925.000000  \n",
       "mean      0.195735  \n",
       "std       0.940599  \n",
       "min      -3.346000  \n",
       "25%      -0.432000  \n",
       "50%       0.152000  \n",
       "75%       0.797000  \n",
       "max       3.021000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data[train_data['V9']>-7.5]\n",
    "test_data = test_data[test_data['V9']>-7.5]\n",
    "train_data.describe()\n",
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 归一化处理\n",
    "from sklearn import preprocessing \n",
    "features_columns = [col for col in train_data.columns if col not in ['target']]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "min_max_scaler = min_max_scaler.fit(train_data[features_columns])\n",
    "train_data_scaler = min_max_scaler.transform(train_data[features_columns])\n",
    "test_data_scaler = min_max_scaler.transform(test_data[features_columns])\n",
    "train_data_scaler = pd.DataFrame(train_data_scaler)\n",
    "train_data_scaler.columns = features_columns\n",
    "test_data_scaler = pd.DataFrame(test_data_scaler)\n",
    "test_data_scaler.columns = features_columns\n",
    "train_data_scaler['target'] = train_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PCA方法降维\n",
    "from sklearn.decomposition import PCA   #主成分分析法\n",
    "#保留16个主成分\n",
    "pca = PCA(n_components=16)\n",
    "new_train_pca_16 = pca.fit_transform(train_data_scaler.iloc[:,0:-1])\n",
    "new_test_pca_16 = pca.transform(test_data_scaler)\n",
    "new_train_pca_16 = pd.DataFrame(new_train_pca_16)\n",
    "new_test_pca_16 = pd.DataFrame(new_test_pca_16)\n",
    "new_train_pca_16['target'] = train_data_scaler['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#保留16维特征并切分数据\n",
    "new_train_pca_16 = new_train_pca_16.fillna(0)\n",
    "train = new_train_pca_16[new_test_pca_16.columns]\n",
    "target = new_train_pca_16['target']\n",
    "# 切分数据 训练数据80% 验证数据20%\n",
    "train_data, test_data, train_target, test_target = train_test_split(\n",
    "    train, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 欠拟合情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor train MSE:    0.151463981412985\n",
      "SGDRegressor test MSE:    0.15582443408189456\n"
     ]
    }
   ],
   "source": [
    "clf = SGDRegressor(max_iter=500, tol=1e-2) \n",
    "clf.fit(train_data, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor test MSE:   \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 过拟合情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor train MSE:    0.1330248157674981\n",
      "SGDRegressor test MSE:    0.14559928859802745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(5)\n",
    "train_data_poly = poly.fit_transform(train_data)\n",
    "test_data_poly = poly.transform(test_data)\n",
    "clf = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "clf.fit(train_data_poly, train_target)\n",
    "score_train = mean_squared_error(train_target, \n",
    "                                 clf.predict(train_data_poly))\n",
    "score_test = mean_squared_error(test_target, \n",
    "                                clf.predict(test_data_poly))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor test MSE:   \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正常拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor train MSE:    0.13423885909686148\n",
      "SGDRegressor test MSE:    0.1427494025552031\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(3)\n",
    "train_data_poly = poly.fit_transform(train_data)\n",
    "test_data_poly = poly.transform(test_data)\n",
    "clf = SGDRegressor(max_iter=1000, tol=1e-3) \n",
    "clf.fit(train_data_poly, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data_poly))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data_poly))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor test MSE:   \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型正则化\n",
    "\n",
    "**L2范数正则化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor train MSE:    0.13323787756476335\n",
      "SGDRegressor test MSE:    0.14187259762046708\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(3)\n",
    "train_data_poly = poly.fit_transform(train_data)\n",
    "test_data_poly = poly.transform(test_data)\n",
    "clf = SGDRegressor(max_iter=1000, tol=1e-3, penalty= 'L2', alpha=0.0001) \n",
    "clf.fit(train_data_poly, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data_poly))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data_poly))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor test MSE:   \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L1范数正则化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor train MSE:    0.13511036183307598\n",
      "SGDRegressor test MSE:    0.14332864452241414\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(3)\n",
    "train_data_poly = poly.fit_transform(train_data)\n",
    "test_data_poly = poly.transform(test_data)\n",
    "clf = SGDRegressor(max_iter=1000, tol=1e-3, penalty= 'L1', alpha=0.00001) \n",
    "clf.fit(train_data_poly, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data_poly))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data_poly))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor test MSE:   \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型交叉验证\n",
    "\n",
    "**简单交叉验证 Hold-out-menthod**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor train MSE:    0.14161348155004896\n",
      "SGDRegressor test MSE:    0.14710821468956675\n"
     ]
    }
   ],
   "source": [
    "# 简单交叉验证\n",
    "from sklearn.model_selection import train_test_split  # 切分数据\n",
    "# 切分数据 训练数据80% 验证数据20%\n",
    "train_data, test_data, train_target, test_target = train_test_split(\n",
    "    train, target, test_size=0.2, random_state=0)\n",
    "\n",
    "clf = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "clf.fit(train_data, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "print(\"SGDRegressor train MSE:   \", score_train)\n",
    "print(\"SGDRegressor test MSE:   \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K折交叉验证 K-fold CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  折 SGDRegressor train MSE:    0.14987519063138968\n",
      "0  折 SGDRegressor test MSE:    0.1060328439968145 \n",
      "\n",
      "1  折 SGDRegressor train MSE:    0.13348513688408262\n",
      "1  折 SGDRegressor test MSE:    0.18223249632622965 \n",
      "\n",
      "2  折 SGDRegressor train MSE:    0.14726773006341226\n",
      "2  折 SGDRegressor test MSE:    0.1333875735612879 \n",
      "\n",
      "3  折 SGDRegressor train MSE:    0.14070672027424191\n",
      "3  折 SGDRegressor test MSE:    0.16188645467771542 \n",
      "\n",
      "4  折 SGDRegressor train MSE:    0.1387380473396963\n",
      "4  折 SGDRegressor test MSE:    0.16578847813134126 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5折交叉验证\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "for k, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "    train_data, test_data, train_target, test_target = train.values[\n",
    "        train_index], train.values[test_index], target[train_index], target[\n",
    "            test_index]\n",
    "    clf = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "    clf.fit(train_data, train_target)\n",
    "    score_train = mean_squared_error(train_target, clf.predict(train_data))\n",
    "    score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "    print(k, \" 折\", \"SGDRegressor train MSE:   \", score_train)\n",
    "    print(k, \" 折\", \"SGDRegressor test MSE:   \", score_test, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**留一法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  个 SGDRegressor train MSE:    0.1416361883685269\n",
      "0  个 SGDRegressor test MSE:    0.010073006442686173 \n",
      "\n",
      "1  个 SGDRegressor train MSE:    0.14150088537573924\n",
      "1  个 SGDRegressor test MSE:    0.12223831229426645 \n",
      "\n",
      "2  个 SGDRegressor train MSE:    0.14151483414511198\n",
      "2  个 SGDRegressor test MSE:    0.03860355577845687 \n",
      "\n",
      "3  个 SGDRegressor train MSE:    0.14159754755399034\n",
      "3  个 SGDRegressor test MSE:    0.0036852651965835117 \n",
      "\n",
      "4  个 SGDRegressor train MSE:    0.1416319203961655\n",
      "4  个 SGDRegressor test MSE:    0.012302690522310006 \n",
      "\n",
      "5  个 SGDRegressor train MSE:    0.14092006868236745\n",
      "5  个 SGDRegressor test MSE:    0.14565501477002468 \n",
      "\n",
      "6  个 SGDRegressor train MSE:    0.1415255897987022\n",
      "6  个 SGDRegressor test MSE:    0.02482892017395111 \n",
      "\n",
      "7  个 SGDRegressor train MSE:    0.14100323573907528\n",
      "7  个 SGDRegressor test MSE:    0.0013065832128669186 \n",
      "\n",
      "8  个 SGDRegressor train MSE:    0.14158099844010494\n",
      "8  个 SGDRegressor test MSE:    0.08967848274344706 \n",
      "\n",
      "9  个 SGDRegressor train MSE:    0.14171420289072534\n",
      "9  个 SGDRegressor test MSE:    0.053225316980442985 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "num = 100\n",
    "for k, (train_index, test_index) in enumerate(loo.split(train)):\n",
    "    train_data, test_data, train_target, test_target = train.values[\n",
    "        train_index], train.values[test_index], target[train_index], target[\n",
    "            test_index]\n",
    "    clf = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "    clf.fit(train_data, train_target)\n",
    "    score_train = mean_squared_error(train_target, clf.predict(train_data))\n",
    "    score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "    print(k, \" 个\", \"SGDRegressor train MSE:   \", score_train)\n",
    "    print(k, \" 个\", \"SGDRegressor test MSE:   \", score_test, '\\n')\n",
    "    if k >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**留P法 LPO CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  10个 SGDRegressor train MSE:    0.14190833532181063\n",
      "0  10个 SGDRegressor test MSE:    0.04941961238187924 \n",
      "\n",
      "1  10个 SGDRegressor train MSE:    0.14138481844698866\n",
      "1  10个 SGDRegressor test MSE:    0.04372153210164471 \n",
      "\n",
      "2  10个 SGDRegressor train MSE:    0.14205969283287678\n",
      "2  10个 SGDRegressor test MSE:    0.04594238283760854 \n",
      "\n",
      "3  10个 SGDRegressor train MSE:    0.141949223537575\n",
      "3  10个 SGDRegressor test MSE:    0.05446609330153962 \n",
      "\n",
      "4  10个 SGDRegressor train MSE:    0.14194814408072978\n",
      "4  10个 SGDRegressor test MSE:    0.06901778463810983 \n",
      "\n",
      "5  10个 SGDRegressor train MSE:    0.1419081890636233\n",
      "5  10个 SGDRegressor test MSE:    0.0451405014060003 \n",
      "\n",
      "6  10个 SGDRegressor train MSE:    0.14197777894847222\n",
      "6  10个 SGDRegressor test MSE:    0.049461335330664456 \n",
      "\n",
      "7  10个 SGDRegressor train MSE:    0.14192898721929645\n",
      "7  10个 SGDRegressor test MSE:    0.05282934484860422 \n",
      "\n",
      "8  10个 SGDRegressor train MSE:    0.14197706873590443\n",
      "8  10个 SGDRegressor test MSE:    0.04731840934915386 \n",
      "\n",
      "9  10个 SGDRegressor train MSE:    0.14190313872122215\n",
      "9  10个 SGDRegressor test MSE:    0.04533394302230206 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeavePOut\n",
    "lpo = LeavePOut(p=10)\n",
    "num = 100\n",
    "for k, (train_index, test_index) in enumerate(lpo.split(train)):\n",
    "    train_data, test_data, train_targetarget, test_target = train.values[\n",
    "        train_index], train.values[test_index], target[train_index], target[\n",
    "            test_index]\n",
    "    clf = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "    clf.fit(train_data, train_target)\n",
    "    score_train = mean_squared_error(train_target, clf.predict(train_data))\n",
    "    score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "    print(k, \" 10个\", \"SGDRegressor train MSE:   \", score_train)\n",
    "    print(k, \" 10个\", \"SGDRegressor test MSE:   \", score_test, '\\n')\n",
    "    if k >= 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型超参空间及调参\n",
    "\n",
    "**穷举网格搜索**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor GridSearchCV test MSE:    0.256107108970348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_max_depth',\n",
       " 'param_n_estimators',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split  # 切分数据\n",
    "# 切分数据 训练数据80% 验证数据20%\n",
    "train_data, test_data, train_target, test_target = train_test_split(\n",
    "    train, target, test_size=0.2, random_state=0)\n",
    "\n",
    "randomForestRegressor = RandomForestRegressor()\n",
    "parameters = {'n_estimators': [50, 100, 200], 'max_depth': [1, 2, 3]}\n",
    "clf = GridSearchCV(randomForestRegressor, parameters, cv=5)\n",
    "clf.fit(train_data, train_target)\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "\n",
    "print(\"RandomForestRegressor GridSearchCV test MSE:   \", score_test)\n",
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**随机参数优化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor RandomizedSearchCV test MSE:    0.19636861894590119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_max_depth',\n",
       " 'param_n_estimators',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split  # 切分数据\n",
    "# 切分数据 训练数据80% 验证数据20%\n",
    "train_data, test_data, train_target, test_target = train_test_split(\n",
    "    train, target, test_size=0.2, random_state=0)\n",
    "\n",
    "randomForestRegressor = RandomForestRegressor()\n",
    "parameters = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [1, 2, 3, 4, 5]\n",
    "}\n",
    "clf = RandomizedSearchCV(randomForestRegressor, parameters, cv=5)\n",
    "clf.fit(train_data, train_target)\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "\n",
    "print(\"RandomForestRegressor RandomizedSearchCV test MSE:   \", score_test)\n",
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lgb 调参**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search are: {'learning_rate': 0.1, 'n_estimators': 40}\n",
      "LGBMRegressor RandomizedSearchCV test MSE:    0.1498258125289947\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "clf = lgb.LGBMRegressor(num_leaves=31)\n",
    "\n",
    "parameters = {'learning_rate': [0.01, 0.1, 1], 'n_estimators': [20, 40]}\n",
    "clf = GridSearchCV(clf, parameters, cv=5)\n",
    "clf.fit(train_data, train_target)\n",
    "\n",
    "print('Best parameters found by grid search are:', clf.best_params_)\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "print(\"LGBMRegressor GridSearchCV test MSE:   \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lgb 线下验证**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tTrain's l2: 0.428458\tTest's l2: 0.466965\n",
      "[100]\tTrain's l2: 0.221807\tTest's l2: 0.263431\n",
      "[150]\tTrain's l2: 0.135301\tTest's l2: 0.183515\n",
      "[200]\tTrain's l2: 0.0958737\tTest's l2: 0.148825\n",
      "[250]\tTrain's l2: 0.075642\tTest's l2: 0.133187\n",
      "[300]\tTrain's l2: 0.0629311\tTest's l2: 0.125237\n",
      "[350]\tTrain's l2: 0.054088\tTest's l2: 0.121321\n",
      "[400]\tTrain's l2: 0.0473551\tTest's l2: 0.118307\n",
      "[450]\tTrain's l2: 0.0418952\tTest's l2: 0.116414\n",
      "[500]\tTrain's l2: 0.0375119\tTest's l2: 0.114863\n",
      "[550]\tTrain's l2: 0.0337062\tTest's l2: 0.114002\n",
      "[600]\tTrain's l2: 0.0303868\tTest's l2: 0.112781\n",
      "[650]\tTrain's l2: 0.02756\tTest's l2: 0.11207\n",
      "[700]\tTrain's l2: 0.0250506\tTest's l2: 0.111287\n",
      "[750]\tTrain's l2: 0.0228758\tTest's l2: 0.110742\n",
      "[800]\tTrain's l2: 0.0209081\tTest's l2: 0.1103\n",
      "[850]\tTrain's l2: 0.0191684\tTest's l2: 0.109946\n",
      "[900]\tTrain's l2: 0.0176066\tTest's l2: 0.109759\n",
      "[950]\tTrain's l2: 0.0162243\tTest's l2: 0.109423\n",
      "[1000]\tTrain's l2: 0.014984\tTest's l2: 0.109105\n",
      "[1050]\tTrain's l2: 0.0138415\tTest's l2: 0.108795\n",
      "[1100]\tTrain's l2: 0.0128086\tTest's l2: 0.108651\n",
      "[1150]\tTrain's l2: 0.0118895\tTest's l2: 0.10835\n",
      "[1200]\tTrain's l2: 0.0110348\tTest's l2: 0.108169\n",
      "[1250]\tTrain's l2: 0.0102351\tTest's l2: 0.107997\n",
      "[1300]\tTrain's l2: 0.00949631\tTest's l2: 0.107886\n",
      "[1350]\tTrain's l2: 0.00880985\tTest's l2: 0.107708\n",
      "[1400]\tTrain's l2: 0.00818496\tTest's l2: 0.107495\n",
      "[1450]\tTrain's l2: 0.00760212\tTest's l2: 0.107251\n",
      "[1500]\tTrain's l2: 0.00706786\tTest's l2: 0.107126\n",
      "[1550]\tTrain's l2: 0.00657032\tTest's l2: 0.107007\n",
      "[1600]\tTrain's l2: 0.00612321\tTest's l2: 0.10685\n",
      "[1650]\tTrain's l2: 0.00571558\tTest's l2: 0.106697\n",
      "[1700]\tTrain's l2: 0.00532708\tTest's l2: 0.106564\n",
      "[1750]\tTrain's l2: 0.00498736\tTest's l2: 0.106505\n",
      "[1800]\tTrain's l2: 0.0046641\tTest's l2: 0.10643\n",
      "[1850]\tTrain's l2: 0.00435927\tTest's l2: 0.106395\n",
      "[1900]\tTrain's l2: 0.00407441\tTest's l2: 0.106289\n",
      "[1950]\tTrain's l2: 0.00381589\tTest's l2: 0.106228\n",
      "[2000]\tTrain's l2: 0.00358102\tTest's l2: 0.106155\n",
      "[2050]\tTrain's l2: 0.00335863\tTest's l2: 0.106083\n",
      "[2100]\tTrain's l2: 0.00314878\tTest's l2: 0.106064\n",
      "[2150]\tTrain's l2: 0.0029488\tTest's l2: 0.106039\n",
      "[2200]\tTrain's l2: 0.0027557\tTest's l2: 0.105963\n",
      "[2250]\tTrain's l2: 0.00257956\tTest's l2: 0.105857\n",
      "[2300]\tTrain's l2: 0.00242506\tTest's l2: 0.105818\n",
      "[2350]\tTrain's l2: 0.00228008\tTest's l2: 0.105762\n",
      "[2400]\tTrain's l2: 0.00213319\tTest's l2: 0.105696\n",
      "[2450]\tTrain's l2: 0.00199799\tTest's l2: 0.105679\n",
      "[2500]\tTrain's l2: 0.00187769\tTest's l2: 0.10561\n",
      "[2550]\tTrain's l2: 0.0017642\tTest's l2: 0.105564\n",
      "[2600]\tTrain's l2: 0.00165572\tTest's l2: 0.105482\n",
      "[2650]\tTrain's l2: 0.00155773\tTest's l2: 0.105454\n",
      "[2700]\tTrain's l2: 0.0014622\tTest's l2: 0.105423\n",
      "[2750]\tTrain's l2: 0.00137505\tTest's l2: 0.105434\n",
      "Early stopping, best iteration is:\n",
      "[2686]\tTrain's l2: 0.00148912\tTest's l2: 0.105398\n",
      "第1折 训练和预测 训练MSE 预测MSE\n",
      "------\n",
      " 训练MSE\n",
      " 0.0014891170026875996 \n",
      "------\n",
      "------\n",
      " 预测MSE\n",
      " 0.10539809256060707 \n",
      "------\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tTrain's l2: 0.436833\tTest's l2: 0.42889\n",
      "[100]\tTrain's l2: 0.221729\tTest's l2: 0.258452\n",
      "[150]\tTrain's l2: 0.132425\tTest's l2: 0.191434\n",
      "[200]\tTrain's l2: 0.0921422\tTest's l2: 0.164395\n",
      "[250]\tTrain's l2: 0.0715837\tTest's l2: 0.153253\n",
      "[300]\tTrain's l2: 0.0591252\tTest's l2: 0.147273\n",
      "[350]\tTrain's l2: 0.0505444\tTest's l2: 0.143558\n",
      "[400]\tTrain's l2: 0.0442696\tTest's l2: 0.141913\n",
      "[450]\tTrain's l2: 0.0391752\tTest's l2: 0.140459\n",
      "[500]\tTrain's l2: 0.0348435\tTest's l2: 0.139286\n",
      "[550]\tTrain's l2: 0.0313073\tTest's l2: 0.13851\n",
      "[600]\tTrain's l2: 0.0283011\tTest's l2: 0.138002\n",
      "[650]\tTrain's l2: 0.0256303\tTest's l2: 0.136922\n",
      "[700]\tTrain's l2: 0.0233832\tTest's l2: 0.1364\n",
      "[750]\tTrain's l2: 0.0213598\tTest's l2: 0.135964\n",
      "[800]\tTrain's l2: 0.0195432\tTest's l2: 0.135562\n",
      "[850]\tTrain's l2: 0.0179503\tTest's l2: 0.134965\n",
      "[900]\tTrain's l2: 0.0165388\tTest's l2: 0.134784\n",
      "[950]\tTrain's l2: 0.0152956\tTest's l2: 0.134611\n",
      "[1000]\tTrain's l2: 0.0141473\tTest's l2: 0.134473\n",
      "[1050]\tTrain's l2: 0.0130803\tTest's l2: 0.13427\n",
      "[1100]\tTrain's l2: 0.0121275\tTest's l2: 0.134171\n",
      "[1150]\tTrain's l2: 0.0112545\tTest's l2: 0.134014\n",
      "[1200]\tTrain's l2: 0.0104587\tTest's l2: 0.133869\n",
      "[1250]\tTrain's l2: 0.00970802\tTest's l2: 0.133655\n",
      "[1300]\tTrain's l2: 0.00900488\tTest's l2: 0.133415\n",
      "[1350]\tTrain's l2: 0.00834902\tTest's l2: 0.133204\n",
      "[1400]\tTrain's l2: 0.00774199\tTest's l2: 0.132926\n",
      "[1450]\tTrain's l2: 0.00720085\tTest's l2: 0.132728\n",
      "[1500]\tTrain's l2: 0.0067149\tTest's l2: 0.132755\n",
      "Early stopping, best iteration is:\n",
      "[1441]\tTrain's l2: 0.00728983\tTest's l2: 0.132697\n",
      "第2折 训练和预测 训练MSE 预测MSE\n",
      "------\n",
      " 训练MSE\n",
      " 0.0072898318628357595 \n",
      "------\n",
      "------\n",
      " 预测MSE\n",
      " 0.1326966032163865 \n",
      "------\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tTrain's l2: 0.435334\tTest's l2: 0.435477\n",
      "[100]\tTrain's l2: 0.224797\tTest's l2: 0.241969\n",
      "[150]\tTrain's l2: 0.136834\tTest's l2: 0.165256\n",
      "[200]\tTrain's l2: 0.0968498\tTest's l2: 0.134493\n",
      "[250]\tTrain's l2: 0.0761729\tTest's l2: 0.121531\n",
      "[300]\tTrain's l2: 0.0636853\tTest's l2: 0.11448\n",
      "[350]\tTrain's l2: 0.0546683\tTest's l2: 0.110122\n",
      "[400]\tTrain's l2: 0.0479514\tTest's l2: 0.108073\n",
      "[450]\tTrain's l2: 0.0423758\tTest's l2: 0.107005\n",
      "[500]\tTrain's l2: 0.0377975\tTest's l2: 0.105778\n",
      "[550]\tTrain's l2: 0.0339731\tTest's l2: 0.104464\n",
      "[600]\tTrain's l2: 0.0306455\tTest's l2: 0.103408\n",
      "[650]\tTrain's l2: 0.0278085\tTest's l2: 0.10251\n",
      "[700]\tTrain's l2: 0.0252935\tTest's l2: 0.101614\n",
      "[750]\tTrain's l2: 0.0231005\tTest's l2: 0.101372\n",
      "[800]\tTrain's l2: 0.021199\tTest's l2: 0.101199\n",
      "[850]\tTrain's l2: 0.0194767\tTest's l2: 0.101142\n",
      "[900]\tTrain's l2: 0.0179671\tTest's l2: 0.101309\n",
      "Early stopping, best iteration is:\n",
      "[821]\tTrain's l2: 0.020451\tTest's l2: 0.101119\n",
      "第3折 训练和预测 训练MSE 预测MSE\n",
      "------\n",
      " 训练MSE\n",
      " 0.0204510246350711 \n",
      "------\n",
      "------\n",
      " 预测MSE\n",
      " 0.10111932554955039 \n",
      "------\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tTrain's l2: 0.424194\tTest's l2: 0.486322\n",
      "[100]\tTrain's l2: 0.22045\tTest's l2: 0.264404\n",
      "[150]\tTrain's l2: 0.13572\tTest's l2: 0.178101\n",
      "[200]\tTrain's l2: 0.0968777\tTest's l2: 0.144088\n",
      "[250]\tTrain's l2: 0.0765346\tTest's l2: 0.129439\n",
      "[300]\tTrain's l2: 0.0639781\tTest's l2: 0.122908\n",
      "[350]\tTrain's l2: 0.0552914\tTest's l2: 0.118902\n",
      "[400]\tTrain's l2: 0.0485628\tTest's l2: 0.115741\n",
      "[450]\tTrain's l2: 0.0429733\tTest's l2: 0.114079\n",
      "[500]\tTrain's l2: 0.0383471\tTest's l2: 0.11299\n",
      "[550]\tTrain's l2: 0.0344226\tTest's l2: 0.112069\n",
      "[600]\tTrain's l2: 0.0311593\tTest's l2: 0.111212\n",
      "[650]\tTrain's l2: 0.0283902\tTest's l2: 0.110788\n",
      "[700]\tTrain's l2: 0.0258853\tTest's l2: 0.110003\n",
      "[750]\tTrain's l2: 0.0236758\tTest's l2: 0.109461\n",
      "[800]\tTrain's l2: 0.0217031\tTest's l2: 0.108945\n",
      "[850]\tTrain's l2: 0.019937\tTest's l2: 0.10856\n",
      "[900]\tTrain's l2: 0.0183338\tTest's l2: 0.108237\n",
      "[950]\tTrain's l2: 0.0168597\tTest's l2: 0.107832\n",
      "[1000]\tTrain's l2: 0.0155639\tTest's l2: 0.107673\n",
      "[1050]\tTrain's l2: 0.0143787\tTest's l2: 0.107542\n",
      "[1100]\tTrain's l2: 0.0132679\tTest's l2: 0.107417\n",
      "[1150]\tTrain's l2: 0.0123009\tTest's l2: 0.107295\n",
      "[1200]\tTrain's l2: 0.0113964\tTest's l2: 0.107125\n",
      "[1250]\tTrain's l2: 0.0105699\tTest's l2: 0.10694\n",
      "[1300]\tTrain's l2: 0.00982176\tTest's l2: 0.106933\n",
      "[1350]\tTrain's l2: 0.00913726\tTest's l2: 0.106855\n",
      "[1400]\tTrain's l2: 0.00849822\tTest's l2: 0.106897\n",
      "Early stopping, best iteration is:\n",
      "[1334]\tTrain's l2: 0.00935585\tTest's l2: 0.106822\n",
      "第4折 训练和预测 训练MSE 预测MSE\n",
      "------\n",
      " 训练MSE\n",
      " 0.009355847634266076 \n",
      "------\n",
      "------\n",
      " 预测MSE\n",
      " 0.10682190098205552 \n",
      "------\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tTrain's l2: 0.435061\tTest's l2: 0.446282\n",
      "[100]\tTrain's l2: 0.224844\tTest's l2: 0.252081\n",
      "[150]\tTrain's l2: 0.136923\tTest's l2: 0.172668\n",
      "[200]\tTrain's l2: 0.0962587\tTest's l2: 0.13786\n",
      "[250]\tTrain's l2: 0.0754087\tTest's l2: 0.122259\n",
      "[300]\tTrain's l2: 0.0625492\tTest's l2: 0.114111\n",
      "[350]\tTrain's l2: 0.05372\tTest's l2: 0.109744\n",
      "[400]\tTrain's l2: 0.0469531\tTest's l2: 0.106481\n",
      "[450]\tTrain's l2: 0.0415226\tTest's l2: 0.104888\n",
      "[500]\tTrain's l2: 0.0370845\tTest's l2: 0.103151\n",
      "[550]\tTrain's l2: 0.033334\tTest's l2: 0.102501\n",
      "[600]\tTrain's l2: 0.0301713\tTest's l2: 0.101926\n",
      "[650]\tTrain's l2: 0.027339\tTest's l2: 0.101613\n",
      "[700]\tTrain's l2: 0.0249321\tTest's l2: 0.10139\n",
      "[750]\tTrain's l2: 0.0228313\tTest's l2: 0.101207\n",
      "[800]\tTrain's l2: 0.0209294\tTest's l2: 0.100924\n",
      "[850]\tTrain's l2: 0.0192055\tTest's l2: 0.100718\n",
      "[900]\tTrain's l2: 0.0176946\tTest's l2: 0.100402\n",
      "[950]\tTrain's l2: 0.0163089\tTest's l2: 0.100187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tTrain's l2: 0.0150397\tTest's l2: 0.099986\n",
      "[1050]\tTrain's l2: 0.0138704\tTest's l2: 0.0998263\n",
      "[1100]\tTrain's l2: 0.0128394\tTest's l2: 0.0996427\n",
      "[1150]\tTrain's l2: 0.0118688\tTest's l2: 0.0996074\n",
      "[1200]\tTrain's l2: 0.0110126\tTest's l2: 0.0995783\n",
      "[1250]\tTrain's l2: 0.0102254\tTest's l2: 0.0995361\n",
      "[1300]\tTrain's l2: 0.00951201\tTest's l2: 0.0993949\n",
      "[1350]\tTrain's l2: 0.00884199\tTest's l2: 0.0992683\n",
      "[1400]\tTrain's l2: 0.00822777\tTest's l2: 0.0993064\n",
      "[1450]\tTrain's l2: 0.00767529\tTest's l2: 0.0992335\n",
      "[1500]\tTrain's l2: 0.00712999\tTest's l2: 0.0992797\n",
      "Early stopping, best iteration is:\n",
      "[1423]\tTrain's l2: 0.00797142\tTest's l2: 0.0992124\n",
      "第5折 训练和预测 训练MSE 预测MSE\n",
      "------\n",
      " 训练MSE\n",
      " 0.007971416523938925 \n",
      "------\n",
      "------\n",
      " 预测MSE\n",
      " 0.09921237825179019 \n",
      "------\n",
      "\n",
      "------\n",
      " 训练MSE\n",
      " [0.0014891170026875996, 0.0072898318628357595, 0.0204510246350711, 0.009355847634266076, 0.007971416523938925] \n",
      " 0.009311447531759892 \n",
      "------\n",
      "------\n",
      " 预测MSE\n",
      " [0.10539809256060707, 0.1326966032163865, 0.10111932554955039, 0.10682190098205552, 0.09921237825179019] \n",
      " 0.10904966011207792 \n",
      "------\n"
     ]
    }
   ],
   "source": [
    "train_data2 = pd.read_csv('./zhengqi_train.txt', sep='\\t')\n",
    "test_data2 = pd.read_csv('./zhengqi_test.txt', sep='\\t')\n",
    "\n",
    "train_data2_f = train_data2[test_data2.columns].values\n",
    "train_data2_target = train_data2['target'].values\n",
    "\n",
    "# lgb 模型\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "# 5折交叉验证\n",
    "Folds = 5\n",
    "kf = KFold(n_splits=Folds, shuffle=True, random_state=2019)\n",
    "# 记录训练和预测MSE\n",
    "MSE_DICT = {'train_mse': [], 'test_mse': []}\n",
    "\n",
    "# 线下训练预测\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_data2_f)):\n",
    "    # lgb树模型\n",
    "    lgb_reg = lgb.LGBMRegressor(\n",
    "        learning_rate=0.01,\n",
    "        max_depth=-1,\n",
    "        n_estimators=5000,\n",
    "        boosting_type='gbdt',\n",
    "        random_state=2019,\n",
    "        objective='regression',\n",
    "    )\n",
    "    # 切分训练集和预测集\n",
    "    X_train_KFold, X_test_KFold = train_data2_f[train_index], train_data2_f[\n",
    "        test_index]\n",
    "    y_train_KFold, y_test_KFold = train_data2_target[\n",
    "        train_index], train_data2_target[test_index]\n",
    "    # 训练模型\n",
    "    lgb_reg.fit(X=X_train_KFold,\n",
    "                y=y_train_KFold,\n",
    "                eval_set=[(X_train_KFold, y_train_KFold),\n",
    "                          (X_test_KFold, y_test_KFold)],\n",
    "                eval_names=['Train', 'Test'],\n",
    "                early_stopping_rounds=100,\n",
    "                eval_metric='MSE',\n",
    "                verbose=50)\n",
    "\n",
    "    # 训练集预测 测试集预测\n",
    "    y_train_KFold_predict = lgb_reg.predict(\n",
    "        X_train_KFold, num_iteration=lgb_reg.best_iteration_)\n",
    "    y_test_KFold_predict = lgb_reg.predict(\n",
    "        X_test_KFold, num_iteration=lgb_reg.best_iteration_)\n",
    "\n",
    "    print('第{}折 训练和预测 训练MSE 预测MSE'.format(i + 1))\n",
    "    train_mse = mean_squared_error(y_train_KFold_predict, y_train_KFold)\n",
    "    print('------\\n', '训练MSE\\n', train_mse, '\\n------')\n",
    "    test_mse = mean_squared_error(y_test_KFold_predict, y_test_KFold)\n",
    "    print('------\\n', '预测MSE\\n', test_mse, '\\n------\\n')\n",
    "\n",
    "    MSE_DICT['train_mse'].append(train_mse)\n",
    "    MSE_DICT['test_mse'].append(test_mse)\n",
    "print('------\\n', '训练MSE\\n', MSE_DICT['train_mse'], '\\n',\n",
    "      np.mean(MSE_DICT['train_mse']), '\\n------')\n",
    "print('------\\n', '预测MSE\\n', MSE_DICT['test_mse'], '\\n',\n",
    "      np.mean(MSE_DICT['test_mse']), '\\n------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
